% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_functions.R
\name{gen_txt}
\alias{gen_txt}
\alias{gen_txt.default}
\alias{gen_txt.genflow_agent}
\title{Generate text via multiple providers}
\usage{
gen_txt(context, ...)

\method{gen_txt}{default}(
  context,
  res_context = TRUE,
  add = NULL,
  add_img = NULL,
  directory = NULL,
  label = NULL,
  service = "openai",
  model = "gpt-5-mini",
  temp = 1,
  reasoning = NULL,
  tools = FALSE,
  plugins = NULL,
  my_tools = NULL,
  timeout_api = 240,
  null_repeat = TRUE,
  ...
)

\method{gen_txt}{genflow_agent}(context, ...)
}
\arguments{
\item{context}{Character or object; main prompt or context. Non-character values
are stringified.}

\item{...}{Additional arguments passed to method-specific implementations.}

\item{res_context}{Logical; whether to persist the original \code{context} alongside
the response when saving.}

\item{add}{Optional; additional content to append to \code{context}. Accepts character
strings, file paths (\code{.txt}/\code{.csv}), data frames, matrices, or lists.}

\item{add_img}{Optional character; path to an image file to include (for
multimodal-capable models).}

\item{directory}{Character; directory to save responses and metadata. Defaults
to \code{tools::R_user_dir("agent_models", which = "data")} when \code{NULL}.}

\item{label}{Optional character; label for the saved response. Defaults to a
sanitized derivation of \code{context}.}

\item{service}{Character; provider identifier (e.g. \code{"openai"},
\code{"openrouter"}, \code{"hf"}, \code{"ollama"}, \code{"llamacpp"}).}

\item{model}{Character; model identifier for the chosen \code{service}.}

\item{temp}{Optional numeric; sampling temperature. If \code{NULL}, defaults to 0.7.}

\item{reasoning}{One of minimal, low, medium, high, or xhigh.}

\item{tools}{Logical; whether to enable tool/function calling for providers
that support it.}

\item{plugins}{Optional list or JSON string describing provider-specific
plugins/extensions to include in the request.}

\item{my_tools}{Function; your function with tools definitions.}

\item{timeout_api}{Numeric; request timeout (seconds) passed to the provider
call.}

\item{null_repeat}{Logical; if \code{TRUE}, retries on empty responses with
progressive waits (10s, 60s, 600s).}
}
\value{
A list with elements: \code{response_value}, \code{label}, \code{label_cat},
\code{service}, \code{model}, \code{temp}, \code{duration}, \code{status_api}, \code{status_msg},
\code{tokens_sent}, \code{tokens_received}.
}
\description{
High-level helper to send a prompt (and optional additional content and image)
to a selected provider/model using a unified interface. Handles timeouts,
retries on empty results, basic token estimation, and optional persistence of
requests and responses through \code{.save_response}.
}
\examples{
\dontrun{
gen_txt(
  context = "Summarize this paragraph:",
  add = "Large language models can help with many tasks...",
  service = "openai",
  model = "gpt-4o-mini",
  temp = 0.3
)
}
}
